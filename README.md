## 데이터 엔지니어 과제 제출

### 개요
---
본 저장소는 데이터 엔지니어 과제 수행 결과를 정리한 것입니다.
과제는 총 2개로 구성되어 있으며, Python을 활용한 텍스트 분석 과제와 시스템 아키텍처 설계 과제로 나뉘어 있습니다.  

## 디렉터리 구조
---
├── assignment1 # 과제 1: 단어 분석
│   ├── assignment1_word_analysis.py 
│   └── example.txt # 입력 파일
├── assignment2 # 과제 2: 아키텍처 설계 문서
│   └── assignment2_architecture.md
└── README.md # 과제 설명  

## 과제 1 : 단어 세기
---
**과제 목적**  
1. 텍스트에서 단어 `Rebecca`의 등장 횟수 세기
2. 4글자 이상 단어 중 가장 많이 등장한 단어를 상위 5개 추출

**설계 및 구현 의도**  
- 단어 추출과 필터링을 한 번에 처리하기 위해 정규포현식 `re.findall()`을 사용했습니다.
- 단어 수 세기에는 해시 기반의 `collections.Counter`를 활용하여 O(n) 시간복잡도로 빠르게 처리할 수 있도록 했습니다.
- 단어 경계 인식을 위해 `\b`를 사용하여 정확히 일치하는 단어만 추출하도록 했습니다.
- 초기에 MapReduce 방식도 고려하였으나, 본 과제의 입력 텍스트 크기가 9KB 수준으로 작아 단일 스레드, 단일 프로세스 처리가 훨씬 효율적이라고 판단했습니다.
- 실제 분산 처리 환경은 I/O 오버헤드가 크기 때문에, 이 경우에는 오히려 성능이 저하될 수 있어 적용하지 않았습니다.

**"효율적"에 대한 판단 기준**  
- 성능: O(n) 처리 가능한 Counter 사용
- 가독성: 한눈에 구조가 드러나는 코드 (정규표현식 + 표준 라이브러리 위주)
- 확장성: 최소한의 수정으로 다른 분석에도 쉽게 적용 가능
- 의존성 최소화: 외부 패키지 없이 Python 기본 기능만 활용

**실행**
```bash
python assignment1/assignment1_word_analysis.py
```
<br>


📘 과제 2: 데이터 파이프라인 구축  
---
**과제 목적**  
1. 실 서비스 영향 없이 상점의 최근 30분 전까지의 집계 데이터(결제 금액 합산, 상품 수) 조회

**설계 및 구현 의도**  
- 일 100만 건의 데이터가 서비스에서 발생될 때, 한 상점의 대략적인 운영 시간이 12시간일 것이라고 추측하여 최근 30분의 데이터는 약 41,700 건의 데이터를 집계하는 것이라고 가정했습니다.

**상세 내용**
- `assignment2/assignment2_architecture.md` 파일 참조